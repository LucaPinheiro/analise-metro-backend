# üöá Guia Completo - Backend Metro SP

Guia completo para instalar, configurar, iniciar e testar o backend do sistema de an√°lise BIM do Metr√¥ de S√£o Paulo.

---

## üìã √çndice

1. [Sobre o Projeto](#sobre-o-projeto)
2. [Pr√©-requisitos](#pr√©-requisitos)
3. [Instala√ß√£o Passo a Passo](#instala√ß√£o-passo-a-passo)
4. [Configura√ß√£o](#configura√ß√£o)
5. [Iniciando o Sistema](#iniciando-o-sistema)
6. [Testando a API](#testando-a-api)
7. [Endpoints Dispon√≠veis](#endpoints-dispon√≠veis)
8. [Troubleshooting](#troubleshooting)

---

## üìñ Sobre o Projeto

Este √© um backend para gerenciamento de pipeline de processamento de imagens e compara√ß√£o BIM para monitoramento de canteiros de obras do Metr√¥ de S√£o Paulo.

### Funcionalidades Principais

- ‚úÖ Upload de modelos BIM (.ifc, .dwg, .obj, .ply)
- ‚úÖ Upload de fotos de canteiro de obras
- ‚úÖ **Importa√ß√£o de arquivos PLY j√° processados**
- ‚úÖ **Deletar projetos** (com limpeza completa de arquivos)
- ‚úÖ Processamento autom√°tico de reconstru√ß√£o 3D (3DGS)
- ‚úÖ Compara√ß√£o Cloud-to-Cloud (C2C) entre BIM e reconstru√ß√£o
- ‚úÖ Monitoramento de progresso em tempo real
- ‚úÖ **Relat√≥rio detalhado de execu√ß√£o**
- ‚úÖ Visualiza√ß√£o de arquivos gerados
- ‚úÖ **Scripts mock para desenvolvimento e MVP**

### Tecnologias

- **Node.js 20+** com **TypeScript**
- **Express.js** - Framework web
- **PostgreSQL 16** - Banco de dados
- **Prisma** - ORM
- **Docker** - Containeriza√ß√£o do banco
- **Multer** - Upload de arquivos

---

## üîß Pr√©-requisitos

Antes de come√ßar, certifique-se de ter instalado:

### Obrigat√≥rios

1. **Node.js 20.x ou superior**
   ```bash
   node --version  # Deve mostrar v20.x ou superior
   ```

2. **npm** (vem com Node.js)
   ```bash
   npm --version
   ```

3. **Docker Desktop** (para banco de dados)
   - macOS: [Download](https://www.docker.com/products/docker-desktop)
   - Windows: [Download](https://www.docker.com/products/docker-desktop)
   - Linux: `sudo apt-get install docker.io docker-compose`

4. **Git** (opcional, para clonar reposit√≥rio)

### Opcionais (para processamento real)

- **CloudCompare** - Para compara√ß√£o C2C
- **COLMAP/Brush** - Para processamento 3DGS
- **jq** - Para formatar JSON no terminal (recomendado)

---

## üöÄ Instala√ß√£o Passo a Passo

### Passo 1: Clonar/Baixar o Projeto

Se voc√™ j√° tem o projeto, pule para o Passo 2.

```bash
# Se for clonar de um reposit√≥rio
git clone <url-do-repositorio>
cd analise-metro-backend

# Ou navegue at√© a pasta do projeto
cd /caminho/para/analise-metro-backend
```

### Passo 2: Instalar Depend√™ncias

```bash
# Instalar todas as depend√™ncias do Node.js
npm install
```

**Tempo estimado:** 1-2 minutos

**O que ser√° instalado:**
- Express, Prisma, Multer, CORS, etc.
- TypeScript e ferramentas de desenvolvimento

### Passo 3: Configurar Banco de Dados com Docker

```bash
# 1. Navegar para pasta docker
cd docker

# 2. Verificar se porta 5432 est√° livre
lsof -i :5432

# Se estiver em uso, pare o PostgreSQL local:
# macOS: brew services stop postgresql
# Linux: sudo systemctl stop postgresql

# 3. Iniciar banco de dados PostgreSQL
docker-compose up -d

# 4. Aguardar inicializa√ß√£o (10-15 segundos)
sleep 10

# 5. Verificar se est√° rodando
docker-compose ps

# Voc√™ deve ver algo como:
# NAME       IMAGE              STATUS
# metro-db   postgres:16-alpine Up X seconds
```

**Se der erro de porta em uso:**
- Op√ß√£o 1: Parar PostgreSQL local
- Op√ß√£o 2: Mudar porta no `docker-compose.yml` (linha 10: `"5433:5432"`)

### Passo 4: Configurar Vari√°veis de Ambiente

```bash
# 1. Voltar para raiz do projeto
cd ..

# 2. Criar arquivo .env
cat > .env << 'EOF'
# Servidor
PORT=3000

# Banco de Dados PostgreSQL
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/metro_pipeline

# Diret√≥rios de Armazenamento
UPLOADS_DIR=./src/shared/data/uploads
OUTPUTS_DIR=./src/shared/data/outputs
LOGS_DIR=./logs

# Configura√ß√µes de Processamento
MAX_CONCURRENT_JOBS=3
JOB_TIMEOUT_MS=3600000

# Ferramentas CLI (configure quando tiver as ferramentas instaladas)
IMAGE_PROCESSING_CLI=./tools/image-processor
BIM_COMPARISON_CLI=CloudCompare
EOF

# 3. Verificar se foi criado
cat .env
```

**Nota:** Se mudou a porta do Docker, atualize `DATABASE_URL`:
```
DATABASE_URL=postgresql://postgres:postgres@localhost:5433/metro_pipeline
```

### Passo 5: Configurar Prisma

```bash
# 1. Gerar cliente Prisma
npx prisma generate

# 2. Sincronizar schema com banco (escolha uma op√ß√£o):

# Op√ß√£o A: Usar migrations (recomendado para primeira vez)
npx prisma migrate dev --name init

# Op√ß√£o B: Usar db push (mais r√°pido, desenvolvimento)
npx prisma db push --accept-data-loss

# 3. Verificar se funcionou
npx prisma migrate status
# Ou
npx prisma db pull
```

**Se der erro "Drift detected":**
```bash
# Resetar banco (CUIDADO: apaga dados!)
cd docker
docker-compose down -v
rm -rf pgdata
docker-compose up -d
cd ..
npx prisma migrate dev --name init
```

### Passo 6: Criar Diret√≥rios Necess√°rios

```bash
# Criar diret√≥rios para uploads e outputs
mkdir -p src/shared/data/uploads
mkdir -p src/shared/data/outputs
mkdir -p logs

# Verificar permiss√µes
chmod -R 755 src/shared/data/
```

### Passo 7: Verificar Instala√ß√£o

```bash
# Verificar se tudo est√° OK
npm run type-check

# Se n√£o houver erros, est√° pronto!
```

---

## ‚öôÔ∏è Configura√ß√£o

### Arquivo .env

O arquivo `.env` cont√©m todas as configura√ß√µes. Principais vari√°veis:

| Vari√°vel | Padr√£o | Descri√ß√£o |
|----------|--------|-----------|
| `PORT` | `3000` | Porta do servidor HTTP |
| `DATABASE_URL` | - | URL de conex√£o PostgreSQL |
| `UPLOADS_DIR` | `./src/shared/data/uploads` | Onde salvar arquivos enviados |
| `OUTPUTS_DIR` | `./src/shared/data/outputs` | Onde salvar resultados |
| `MAX_CONCURRENT_JOBS` | `3` | M√°ximo de processamentos simult√¢neos |
| `IMAGE_PROCESSING_CLI` | `./tools/image-processor` | Caminho para CLI 3DGS |
| `BIM_COMPARISON_CLI` | `CloudCompare` | Caminho para CloudCompare |

### Configurar Ferramentas CLI (Opcional)

Para processamento real, configure os caminhos:

**Windows:**
```bash
IMAGE_PROCESSING_CLI=C:\tools\image-processor.exe
BIM_COMPARISON_CLI="C:\Program Files\CloudCompare\CloudCompare.exe"
```

**Linux/Mac:**
```bash
IMAGE_PROCESSING_CLI=/usr/local/bin/image-processor
BIM_COMPARISON_CLI=/usr/bin/CloudCompare
```

---

## üé¨ Iniciando o Sistema

### 1. Verificar Banco de Dados

```bash
# Verificar se Docker est√° rodando
docker ps

# Verificar se container do banco est√° ativo
cd docker
docker-compose ps

# Se n√£o estiver, iniciar
docker-compose up -d
cd ..
```

### 2. Iniciar Servidor

```bash
# Modo desenvolvimento (com hot-reload)
npm run dev
```

**Voc√™ deve ver:**
```
üöÄ Servidor rodando na porta 3000
üì° Health check: http://localhost:3000/health
üîß API: http://localhost:3000/api
```

### 3. Verificar se Est√° Funcionando

Em outro terminal:

```bash
# Testar health check
curl http://localhost:3000/health

# Deve retornar:
# {"status":"ok","timestamp":"2024-..."}
```

**Se funcionar, o sistema est√° pronto! ‚úÖ**

---

## üß™ Testando a API

### Arquivos de Teste Dispon√≠veis

Voc√™ tem arquivos de teste na raiz do projeto:
- `tinker.obj` - Modelo BIM do cubo m√°gico (241 KB)
- `3dgs.ply` - Reconstru√ß√£o 3DGS completa (6,6 MB)
- `cuboParc.ply` - Reconstru√ß√£o parcial (3,7 MB)

### Teste R√°pido Automatizado

Execute o script de teste:

```bash
# Tornar execut√°vel (se necess√°rio)
chmod +x test-quick.sh

# Executar
./test-quick.sh
```

Este script testa:
- ‚úÖ Health check
- ‚úÖ Criar projeto
- ‚úÖ Listar projetos
- ‚úÖ Obter projeto espec√≠fico
- ‚úÖ Visualizar arquivo BIM

### Testes Manuais Passo a Passo

#### Teste 1: Health Check

```bash
curl http://localhost:3000/health
```

**Resposta esperada:**
```json
{
  "status": "ok",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

#### Teste 2: Criar Projeto

```bash
curl -X POST http://localhost:3000/api/projects \
  -F "name=Cubo M√°gico Teste" \
  -F "description=Teste com cubo m√°gico" \
  -F "modeloBim=@./tinker.obj"
```

**Resposta esperada:**
```json
{
  "id": 1,
  "name": "Cubo M√°gico Teste",
  "description": "Teste com cubo m√°gico",
  "bimPath": "projects/1/modelo.obj",
  "createdAt": "2024-01-01T12:00:00.000Z"
}
```

**Anote o `id` retornado!** (exemplo: 1)

#### Teste 3: Listar Projetos

```bash
curl http://localhost:3000/api/projects
```

**Com formata√ß√£o JSON:**
```bash
curl http://localhost:3000/api/projects | jq
```

#### Teste 4: Obter Projeto Espec√≠fico

```bash
# Substitua 1 pelo ID do seu projeto
curl http://localhost:3000/api/projects/1
```

#### Teste 5: Visualizar Arquivo BIM

```bash
# Substitua 1 pelo ID do projeto
curl http://localhost:3000/api/1/bim/0 -o modelo_baixado.obj

# Verificar se baixou
ls -lh modelo_baixado.obj
```

#### Teste 6: Criar Constru√ß√£o (Alias)

```bash
curl -X POST http://localhost:3000/api/construction \
  -F "name=Cubo M√°gico 2" \
  -F "modeloBim=@./tinker.obj"
```

#### Teste 7: Listar Constru√ß√µes

```bash
curl http://localhost:3000/api/constructions
```

### Testes de Valida√ß√£o

#### Teste: Criar projeto sem arquivo

```bash
curl -X POST http://localhost:3000/api/projects \
  -F "name=Teste Sem Arquivo"
```

**Esperado:** `400 Bad Request` com mensagem de erro

#### Teste: Criar projeto sem nome

```bash
curl -X POST http://localhost:3000/api/projects \
  -F "modeloBim=@./tinker.obj"
```

**Esperado:** `400 Bad Request`

#### Teste: Arquivo inv√°lido

```bash
echo "teste" > test.txt
curl -X POST http://localhost:3000/api/projects \
  -F "name=Teste" \
  -F "modeloBim=@./test.txt"
```

**Esperado:** `400 Bad Request` - "Tipo de arquivo BIM n√£o suportado"

### Testes com Arquivos PLY Existentes

Se voc√™ j√° tem arquivos PLY processados (ex: `3dgs.ply`, `cuboParc.ply`), pode import√°-los diretamente:

#### Importar PLY como Registro

```bash
# Coloque seus arquivos PLY em test-files/ ou na raiz
curl -X POST http://localhost:3000/api/2/records/import-ply \
  -F "name=Registro 3DGS" \
  -F "plyFile=@./test-files/3dgs.ply"
```

**Resposta esperada:**
```json
{
  "id": 1,
  "name": "Registro 3DGS",
  "projectId": 2,
  "recordPath": "2/registros/1/reconstrucao_1.ply",
  "message": "Arquivo PLY importado com sucesso. Use analysis-full para comparar com BIM."
}
```

#### Executar An√°lise com PLY Importado

```bash
# Usar registro espec√≠fico
curl -X POST http://localhost:3000/api/2/analysis-full \
  -H "Content-Type: application/json" \
  -d '{"recordId": 1}'

# Ou deixar o sistema buscar o mais recente automaticamente
curl -X POST http://localhost:3000/api/2/analysis-full \
  -H "Content-Type: application/json" \
  -d '{}'
```

#### Script de Teste Completo

Use o script `test-complete.sh` para testar todo o fluxo:

```bash
# Certifique-se de que os arquivos PLY est√£o dispon√≠veis
# Em test-files/ ou na raiz do projeto
./test-complete.sh
```

Este script testa:
1. Health check
2. Cria√ß√£o de projeto
3. Importa√ß√£o de PLY (3dgs.ply)
4. Importa√ß√£o de segundo PLY (cuboParc.ply)
5. Listagem de registros
6. In√≠cio de an√°lise C2C
7. Verifica√ß√£o de status
8. Listagem de an√°lises

### Testes com Fotos (Requer Fotos Reais)

Para testar upload de fotos e processamento, voc√™ precisa de fotos reais (JPG/PNG).

#### Criar Registro com Fotos

```bash
curl -X POST http://localhost:3000/api/projects/1/records \
  -F "name=Registro Semana 1" \
  -F "fotos=@./foto1.jpg" \
  -F "fotos=@./foto2.jpg" \
  -F "fotos=@./foto3.jpg"
```

**Requisitos:**
- M√≠nimo 3 fotos
- Tipos: .jpg, .jpeg, .png
- Tamanho: 100KB - 100MB por foto

#### Processamento Completo

```bash
curl -X POST http://localhost:3000/api/1/photo-processing-full \
  -F "name=Registro Completo" \
  -F "fotos=@./foto1.jpg" \
  -F "fotos=@./foto2.jpg" \
  -F "fotos=@./foto3.jpg"
```

**Resposta:**
```json
{
  "analysisId": 1,
  "recordId": 1,
  "status": "pending",
  "message": "Processamento completo iniciado",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

#### Monitorar Progresso

```bash
# Substitua 1 pelo analysisId retornado
curl http://localhost:3000/api/analyses/1

# Ou com formata√ß√£o
curl http://localhost:3000/api/analyses/1 | jq
```

**Status poss√≠veis:**
- `pending` - Aguardando processamento
- `processing` - Em processamento
- `completed` - Conclu√≠do
- `failed` - Falhou
- `cancelled` - Cancelado

#### Relat√≥rio de Execu√ß√£o

```bash
curl http://localhost:3000/api/analyses/1/report | jq
```

Retorna relat√≥rio completo com:
- Informa√ß√µes da an√°lise (dura√ß√£o, progresso)
- Etapas executadas
- M√©tricas calculadas
- Arquivos gerados
- Logs completos

---

## üì° Endpoints Dispon√≠veis

### Health Check

```
GET /health
```

Retorna status do servidor.

### Projetos

#### Criar Projeto
```
POST /api/projects
Content-Type: multipart/form-data
Body:
  - name: string (obrigat√≥rio)
  - description: string (opcional)
  - modeloBim: file (obrigat√≥rio, .ifc/.dwg/.obj/.ply)
```

#### Listar Projetos
```
GET /api/projects
```

#### Obter Projeto
```
GET /api/projects/:id
```

#### Deletar Projeto
```
DELETE /api/projects/:id
```

**Descri√ß√£o:** Deleta um projeto e todos os dados relacionados (registros, an√°lises e arquivos f√≠sicos).

**Exemplo:**
```bash
curl -X DELETE http://localhost:3000/api/projects/1
```

**Resposta:**
```json
{
  "message": "Projeto deletado com sucesso",
  "projectId": 1,
  "deletedFiles": {
    "bim": true,
    "records": 2,
    "analyses": 3
  }
}
```

**Aten√ß√£o:** Esta opera√ß√£o √© irrevers√≠vel e remove:
- Projeto do banco de dados
- Todos os registros relacionados (cascade)
- Todas as an√°lises relacionadas (cascade)
- Arquivo BIM do sistema de arquivos
- Todas as fotos dos registros
- Todos os arquivos de output (reconstru√ß√µes e an√°lises)

### Constru√ß√µes (Alias)

#### Criar Constru√ß√£o
```
POST /api/construction
```
Igual a criar projeto.

#### Listar Constru√ß√µes
```
GET /api/constructions
```

### Registros

#### Adicionar Registro
```
POST /api/projects/:id/records
Content-Type: multipart/form-data
Body:
  - name: string (obrigat√≥rio)
  - fotos: file[] (obrigat√≥rio, m√≠nimo 3, .jpg/.jpeg/.png)
```

#### Listar Registros
```
GET /api/projects/:id/records
```

#### Importar PLY Existente
```
POST /api/:constructionId/records/import-ply
Content-Type: multipart/form-data
Body:
  - name: string (obrigat√≥rio)
  - plyFile: file (obrigat√≥rio, .ply)
```

**Descri√ß√£o:** Importa um arquivo PLY j√° processado como registro, sem executar 3DGS. √ötil quando voc√™ j√° tem uma reconstru√ß√£o 3D pronta.

**Exemplo:**
```bash
curl -X POST http://localhost:3000/api/2/records/import-ply \
  -F "name=Registro 3DGS Importado" \
  -F "plyFile=@./test-files/3dgs.ply"
```

**Resposta:**
```json
{
  "id": 1,
  "name": "Registro 3DGS Importado",
  "projectId": 2,
  "recordPath": "2/registros/1/reconstrucao_1.ply",
  "message": "Arquivo PLY importado com sucesso. Use analysis-full para comparar com BIM.",
  "filePath": "2/registros/1/reconstrucao_1.ply"
}
```

**Valida√ß√µes:**
- Arquivo deve ser `.ply`
- Tamanho m√≠nimo: 1KB
- Tamanho m√°ximo: 10GB

### Processamento Completo

#### Photo Processing Full
```
POST /api/:constructionId/photo-processing-full
Content-Type: multipart/form-data
Body:
  - name: string (obrigat√≥rio)
  - fotos: file[] (obrigat√≥rio, m√≠nimo 3)
  - parametros: string (opcional, JSON)
```

Executa: Upload ‚Üí 3DGS ‚Üí C2C automaticamente.

#### Analysis Full
```
POST /api/:constructionId/analysis-full
Content-Type: application/json
Body:
  - recordId: number (opcional)
  - parametros: object (opcional)
```

Executa apenas C2C usando reconstru√ß√£o existente.

### An√°lises

#### Iniciar An√°lise
```
POST /api/analyses
Content-Type: application/json
Body:
  - projectId: number (obrigat√≥rio)
  - recordId: number (obrigat√≥rio)
  - parametros: object (opcional)
```

#### Consultar Status
```
GET /api/analyses/:id
```

#### Listar An√°lises
```
GET /api/analyses
```

#### Listar An√°lises por Projeto
```
GET /api/:constructionId/analyses
```

#### Cancelar An√°lise
```
DELETE /api/analyses/:id
```

### Visualiza√ß√£o

#### Visualizar Arquivo
```
GET /api/:constructionId/:fileType/:fileId
```

**fileType:**
- `bim` - Arquivo BIM do projeto
- `registro` - Reconstru√ß√£o 3DGS
- `analise` - Resultado da an√°lise

**Exemplos:**
```
GET /api/1/bim/0
GET /api/1/registro/1
GET /api/1/analise/1
```

---

## üîç Troubleshooting

### Problema: Porta 5432 j√° est√° em uso

**Sintoma:**
```
Error: Bind for 0.0.0.0:5432 failed: port is already allocated
```

**Solu√ß√£o:**
```bash
# 1. Verificar o que est√° usando
lsof -i :5432

# 2. Parar PostgreSQL local
# macOS:
brew services stop postgresql

# Linux:
sudo systemctl stop postgresql

# 3. Ou mudar porta no docker-compose.yml
# Edite docker/docker-compose.yml linha 10:
ports:
  - "5433:5432"
# E atualize DATABASE_URL no .env
```

### Problema: Drift detectado no Prisma

**Sintoma:**
```
Drift detected: Your database schema is not in sync
```

**Solu√ß√£o:**
```bash
# Op√ß√£o 1: Reset completo (apaga dados!)
cd docker
docker-compose down -v
rm -rf pgdata
docker-compose up -d
cd ..
npx prisma migrate dev --name init

# Op√ß√£o 2: Usar db push (desenvolvimento)
npx prisma db push --accept-data-loss
npx prisma generate
```

### Problema: Servidor n√£o inicia

**Verificar:**
```bash
# 1. Verificar se porta 3000 est√° livre
lsof -i :3000

# 2. Verificar vari√°veis de ambiente
cat .env

# 3. Verificar se Prisma est√° configurado
npx prisma generate

# 4. Verificar logs de erro
npm run dev
```

### Problema: Erro 500 em todos os endpoints

**Solu√ß√£o:**
```bash
# 1. Verificar banco de dados
cd docker
docker-compose ps
docker-compose logs db

# 2. Verificar conex√£o
npx prisma db pull

# 3. Verificar DATABASE_URL no .env
cat .env | grep DATABASE_URL
```

### Problema: Arquivo n√£o encontrado ao fazer upload

**Solu√ß√£o:**
```bash
# 1. Verificar se arquivo existe
ls -lh tinker.obj

# 2. Verificar caminho no comando curl
# Use caminho absoluto se necess√°rio:
curl -X POST http://localhost:3000/api/projects \
  -F "name=Teste" \
  -F "modeloBim=@$(pwd)/tinker.obj"
```

### Problema: Processamento n√£o inicia

**Verificar:**
```bash
# 1. Verificar se ferramentas CLI est√£o configuradas
cat .env | grep CLI

# 2. Verificar se MAX_CONCURRENT_JOBS n√£o est√° no limite
curl http://localhost:3000/api/analyses | jq '.jobs[] | select(.status == "processing")'

# 3. Verificar logs da an√°lise
curl http://localhost:3000/api/analyses/1 | jq '.logs, .error'
```

### Problema: Migration n√£o aplica

**Solu√ß√£o:**
```bash
# 1. Verificar status
npx prisma migrate status

# 2. Aplicar migrations pendentes
npx prisma migrate deploy

# 3. Se houver conflitos
npx prisma migrate reset --force
```

---

## üìù Checklist de Instala√ß√£o

Use este checklist para garantir que tudo est√° configurado:

- [ ] Node.js 20+ instalado
- [ ] Docker instalado e rodando
- [ ] Depend√™ncias instaladas (`npm install`)
- [ ] Banco de dados rodando (`docker-compose ps`)
- [ ] Arquivo `.env` criado e configurado
- [ ] Prisma cliente gerado (`npx prisma generate`)
- [ ] Schema sincronizado (`npx prisma migrate dev` ou `db push`)
- [ ] Diret√≥rios criados (`uploads`, `outputs`, `logs`)
- [ ] Servidor inicia sem erros (`npm run dev`)
- [ ] Health check funciona (`curl http://localhost:3000/health`)

---

## üéØ Pr√≥ximos Passos Ap√≥s Instala√ß√£o

1. **Testar endpoints b√°sicos** - Use o `test-quick.sh`
2. **Configurar ferramentas CLI** - Para processamento real
3. **Testar com fotos reais** - Validar fluxo completo
4. **Integrar com frontend** - Se houver
5. **Configurar produ√ß√£o** - Quando estiver pronto

---

## üìö Estrutura do Projeto

```
analise-metro-backend/
‚îú‚îÄ‚îÄ docker/                 # Configura√ß√£o Docker
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml  # Servi√ßo PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ init.sql           # Script de inicializa√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ pgdata/            # Dados do banco (gitignored)
‚îú‚îÄ‚îÄ prisma/                # Schema e migrations
‚îÇ   ‚îú‚îÄ‚îÄ schema.prisma      # Modelos do banco
‚îÇ   ‚îî‚îÄ‚îÄ migrations/        # Hist√≥rico de migrations
‚îú‚îÄ‚îÄ src/                   # C√≥digo fonte
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/   # Controladores HTTP
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/        # Defini√ß√£o de rotas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/       # L√≥gica de neg√≥cio
‚îÇ   ‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/      # Conex√£o Prisma
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ functions/     # Fun√ß√µes utilit√°rias
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ interfaces/    # Interfaces TypeScript
‚îÇ   ‚îî‚îÄ‚îÄ index.ts           # Ponto de entrada
‚îú‚îÄ‚îÄ test-files/            # Arquivos de teste
‚îú‚îÄ‚îÄ tools/                 # Ferramentas CLI
‚îú‚îÄ‚îÄ .env                   # Vari√°veis de ambiente (criar)
‚îú‚îÄ‚îÄ package.json           # Depend√™ncias
‚îî‚îÄ‚îÄ tsconfig.json          # Configura√ß√£o TypeScript
```

---

## üí° Dicas √öteis

### Usar jq para formatar JSON

```bash
# Instalar jq
# macOS: brew install jq
# Linux: sudo apt-get install jq

# Usar
curl http://localhost:3000/api/projects | jq
```

### Monitorar Logs do Servidor

Em outro terminal, monitore o console onde `npm run dev` est√° rodando.

### Verificar Banco de Dados

```bash
# Abrir Prisma Studio (interface visual)
npx prisma studio

# Ou conectar diretamente
psql postgresql://postgres:postgres@localhost:5432/metro_pipeline
```

### Testar com Postman/Insomnia

1. Importar cole√ß√£o de endpoints
2. Configurar vari√°vel `base_url = http://localhost:3000`
3. Testar endpoints visualmente

---

## üÜò Suporte

Se encontrar problemas:

1. Verifique a se√ß√£o [Troubleshooting](#troubleshooting)
2. Verifique logs do servidor
3. Verifique logs do Docker: `docker-compose logs db`
4. Verifique status do Prisma: `npx prisma migrate status`

---

## ‚úÖ Conclus√£o

Agora voc√™ tem um guia completo para:
- ‚úÖ Instalar o projeto do zero
- ‚úÖ Configurar tudo corretamente
- ‚úÖ Iniciar o servidor
- ‚úÖ Testar todas as funcionalidades
- ‚úÖ Usar scripts mock para desenvolvimento
- ‚úÖ Testar em ambiente produtivo

## üìö Documenta√ß√£o Adicional

Para mais informa√ß√µes, consulte:

- **[README.md](./README.md)** - Guia de in√≠cio r√°pido
- **[DOCS.md](./DOCS.md)** - Documenta√ß√£o t√©cnica completa da API
- **[TESTE_PRODUCAO.md](./TESTE_PRODUCAO.md)** - Guia completo para testes em produ√ß√£o
- **[scripts/README.md](./scripts/README.md)** - Documenta√ß√£o dos scripts de teste
- ‚úÖ Testar todos os endpoints
- ‚úÖ Resolver problemas comuns

**Boa sorte com o projeto! üöÄ**

