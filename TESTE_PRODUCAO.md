# ğŸ§ª Guia de Testes em ProduÃ§Ã£o

Guia completo para testar a aplicaÃ§Ã£o em ambiente produtivo, validando todas as funcionalidades e garantindo que o sistema estÃ¡ funcionando corretamente.

---

## ğŸ“‹ Ãndice

1. [PrÃ©-requisitos](#prÃ©-requisitos)
2. [PreparaÃ§Ã£o do Ambiente](#preparaÃ§Ã£o-do-ambiente)
3. [Checklist de ValidaÃ§Ã£o](#checklist-de-validaÃ§Ã£o)
4. [Testes Funcionais](#testes-funcionais)
5. [Testes de Performance](#testes-de-performance)
6. [Testes de IntegraÃ§Ã£o](#testes-de-integraÃ§Ã£o)
7. [ValidaÃ§Ã£o de Dados](#validaÃ§Ã£o-de-dados)
8. [Monitoramento](#monitoramento)
9. [Troubleshooting](#troubleshooting)

---

## ğŸ”§ PrÃ©-requisitos

### Ambiente de ProduÃ§Ã£o

- âœ… Servidor Node.js 20+ configurado
- âœ… PostgreSQL 16 rodando e acessÃ­vel
- âœ… Docker configurado (se usando container)
- âœ… VariÃ¡veis de ambiente configuradas
- âœ… Ferramentas CLI instaladas (CloudCompare, COLMAP/Brush)
- âœ… EspaÃ§o em disco suficiente (mÃ­nimo 50GB recomendado)
- âœ… PermissÃµes de escrita nos diretÃ³rios de upload/output

### Ferramentas de Teste

- `curl` ou `httpie` para requisiÃ§Ãµes HTTP
- `jq` para formataÃ§Ã£o JSON (recomendado)
- `postman` ou `insomnia` (opcional, para testes GUI)

---

## ğŸš€ PreparaÃ§Ã£o do Ambiente

### 1. Verificar ConfiguraÃ§Ã£o

```bash
# Verificar variÃ¡veis de ambiente
cat .env | grep -v PASSWORD

# Verificar conexÃ£o com banco
npx prisma db pull

# Verificar estrutura de diretÃ³rios
ls -la src/shared/data/
```

### 2. Iniciar ServiÃ§os

```bash
# Banco de dados
cd docker
docker-compose up -d
docker-compose ps

# Servidor (em produÃ§Ã£o, use PM2 ou similar)
npm run build
npm start

# Verificar saÃºde do servidor
curl http://localhost:3000/health
```

### 3. Validar Ferramentas CLI

```bash
# Verificar CloudCompare
which CloudCompare || echo "CloudCompare nÃ£o encontrado"

# Verificar ferramenta 3DGS
which colmap || echo "COLMAP nÃ£o encontrado"

# Testar scripts mock (se usando)
bash tools/fake_3dgs.sh --help 2>&1 | head -5
bash tools/bim-comparison.sh --help 2>&1 | head -5
```

---

## âœ… Checklist de ValidaÃ§Ã£o

### Infraestrutura

- [ ] Servidor respondendo em `/health`
- [ ] Banco de dados conectado e acessÃ­vel
- [ ] DiretÃ³rios de upload/output criados e com permissÃµes
- [ ] VariÃ¡veis de ambiente configuradas corretamente
- [ ] Ferramentas CLI disponÃ­veis e funcionando

### Funcionalidades BÃ¡sicas

- [ ] Criar projeto com BIM
- [ ] Listar projetos
- [ ] Obter projeto especÃ­fico
- [ ] Deletar projeto
- [ ] Criar registro com fotos
- [ ] Importar PLY existente
- [ ] Iniciar processamento completo
- [ ] Consultar status de anÃ¡lise
- [ ] Visualizar arquivos gerados

---

## ğŸ§ª Testes Funcionais

### Teste 1: Health Check

```bash
curl http://localhost:3000/health

# Esperado: {"status":"ok"}
```

### Teste 2: Criar Projeto

```bash
PROJECT_RESPONSE=$(curl -s -X POST http://localhost:3000/api/projects \
  -F "name=Teste ProduÃ§Ã£o $(date +%Y%m%d)" \
  -F "description=Teste funcional em produÃ§Ã£o" \
  -F "modeloBim=@./tinker.obj")

PROJECT_ID=$(echo $PROJECT_RESPONSE | jq -r '.id')

echo "Projeto criado: ID $PROJECT_ID"
```

**ValidaÃ§Ãµes:**
- âœ… Status HTTP 201 ou 200
- âœ… ID retornado Ã© numÃ©rico
- âœ… Arquivo BIM salvo no sistema de arquivos
- âœ… Projeto aparece na listagem

### Teste 3: Listar Projetos

```bash
curl http://localhost:3000/api/projects | jq '.[] | {id, name, createdAt}'
```

**ValidaÃ§Ãµes:**
- âœ… Retorna array de projetos
- âœ… Projeto criado aparece na lista
- âœ… Campos obrigatÃ³rios presentes

### Teste 4: Obter Projeto EspecÃ­fico

```bash
curl http://localhost:3000/api/projects/$PROJECT_ID | jq
```

**ValidaÃ§Ãµes:**
- âœ… Retorna projeto correto
- âœ… Todos os campos presentes
- âœ… `bimPath` aponta para arquivo existente

### Teste 5: Criar Registro com Fotos

```bash
# Criar 5 imagens mock para teste
for i in {1..5}; do
  convert -size 1920x1080 xc:gray +noise random "test_foto_$i.jpg" 2>/dev/null || \
  dd if=/dev/urandom of="test_foto_$i.jpg" bs=1024 count=100
done

RECORD_RESPONSE=$(curl -s -X POST http://localhost:3000/api/projects/$PROJECT_ID/records \
  -F "name=Registro Teste $(date +%H%M%S)" \
  -F "fotos=@./test_foto_1.jpg" \
  -F "fotos=@./test_foto_2.jpg" \
  -F "fotos=@./test_foto_3.jpg" \
  -F "fotos=@./test_foto_4.jpg" \
  -F "fotos=@./test_foto_5.jpg")

RECORD_ID=$(echo $RECORD_RESPONSE | jq -r '.id')
echo "Registro criado: ID $RECORD_ID"
```

**ValidaÃ§Ãµes:**
- âœ… Status HTTP 201
- âœ… Fotos salvas no sistema de arquivos
- âœ… Registro aparece na listagem do projeto

### Teste 6: Processamento Completo (Photo Processing Full)

```bash
ANALYSIS_RESPONSE=$(curl -s -X POST http://localhost:3000/api/$PROJECT_ID/photo-processing-full \
  -F "name=Processamento Completo Teste" \
  -F "fotos=@./test_foto_1.jpg" \
  -F "fotos=@./test_foto_2.jpg" \
  -F "fotos=@./test_foto_3.jpg" \
  -F "fotos=@./test_foto_4.jpg" \
  -F "fotos=@./test_foto_5.jpg")

ANALYSIS_ID=$(echo $ANALYSIS_RESPONSE | jq -r '.analysisId')
echo "AnÃ¡lise iniciada: ID $ANALYSIS_ID"
```

**ValidaÃ§Ãµes:**
- âœ… Status HTTP 202 (Accepted)
- âœ… `analysisId` e `recordId` retornados
- âœ… Status inicial Ã© "pending"

### Teste 7: Monitorar Progresso

```bash
# Aguardar processamento (ajustar tempo conforme necessÃ¡rio)
echo "Aguardando processamento..."
for i in {1..60}; do
  STATUS=$(curl -s http://localhost:3000/api/analyses/$ANALYSIS_ID | jq -r '.status')
  PROGRESS=$(curl -s http://localhost:3000/api/analyses/$ANALYSIS_ID | jq -r '.progress')
  
  echo "[$i/60] Status: $STATUS | Progresso: $PROGRESS%"
  
  if [ "$STATUS" = "completed" ]; then
    echo "âœ… Processamento concluÃ­do!"
    break
  elif [ "$STATUS" = "failed" ]; then
    echo "âŒ Processamento falhou!"
    curl -s http://localhost:3000/api/analyses/$ANALYSIS_ID | jq '.error, .logs[-5:]'
    exit 1
  fi
  
  sleep 5
done
```

**ValidaÃ§Ãµes:**
- âœ… Status muda de "pending" â†’ "processing" â†’ "completed"
- âœ… Progresso aumenta de 0% para 100%
- âœ… Logs sÃ£o atualizados em tempo real
- âœ… Arquivos de saÃ­da sÃ£o gerados

### Teste 8: Verificar Arquivos Gerados

```bash
# Verificar reconstruÃ§Ã£o 3D
ANALYSIS_DATA=$(curl -s http://localhost:3000/api/analyses/$ANALYSIS_ID)
RECORD_PATH=$(echo $ANALYSIS_DATA | jq -r '.outputPaths.modelo3d // empty')
RESULT_PATH=$(echo $ANALYSIS_DATA | jq -r '.resultPath // empty')

if [ -n "$RECORD_PATH" ]; then
  echo "ReconstruÃ§Ã£o 3D: $RECORD_PATH"
  ls -lh "src/shared/data/outputs/$RECORD_PATH" 2>/dev/null || echo "Arquivo nÃ£o encontrado"
fi

if [ -n "$RESULT_PATH" ]; then
  echo "Resultado C2C: $RESULT_PATH"
  ls -lh "src/shared/data/outputs/$RESULT_PATH" 2>/dev/null || echo "Arquivo nÃ£o encontrado"
fi
```

**ValidaÃ§Ãµes:**
- âœ… Arquivo PLY de reconstruÃ§Ã£o existe
- âœ… Arquivo PLY de comparaÃ§Ã£o existe
- âœ… Arquivo JSON de mÃ©tricas existe (se gerado)
- âœ… Tamanhos dos arquivos sÃ£o razoÃ¡veis (> 0 bytes)

### Teste 9: RelatÃ³rio de ExecuÃ§Ã£o

```bash
curl http://localhost:3000/api/analyses/$ANALYSIS_ID/report | jq
```

**ValidaÃ§Ãµes:**
- âœ… RelatÃ³rio completo retornado
- âœ… MÃ©tricas calculadas (mean_distance, std_deviation)
- âœ… DuraÃ§Ã£o do processamento registrada
- âœ… Etapas executadas identificadas

### Teste 10: Visualizar Arquivos

```bash
# Visualizar BIM
curl -I http://localhost:3000/api/$PROJECT_ID/bim/0

# Visualizar reconstruÃ§Ã£o
curl -I http://localhost:3000/api/$PROJECT_ID/registro/$RECORD_ID

# Visualizar anÃ¡lise
curl -I http://localhost:3000/api/$PROJECT_ID/analise/$ANALYSIS_ID
```

**ValidaÃ§Ãµes:**
- âœ… Arquivos sÃ£o servidos corretamente
- âœ… Content-Type apropriado
- âœ… Arquivos nÃ£o estÃ£o vazios

### Teste 11: Importar PLY Existente

```bash
# Se vocÃª tem um arquivo PLY
if [ -f "./3dgs.ply" ]; then
  IMPORT_RESPONSE=$(curl -s -X POST http://localhost:3000/api/$PROJECT_ID/records/import-ply \
    -F "name=PLY Importado Teste" \
    -F "plyFile=@./3dgs.ply")
  
  IMPORT_RECORD_ID=$(echo $IMPORT_RESPONSE | jq -r '.id')
  echo "PLY importado: Record ID $IMPORT_RECORD_ID"
fi
```

**ValidaÃ§Ãµes:**
- âœ… PLY importado com sucesso
- âœ… Arquivo copiado para estrutura correta
- âœ… `recordPath` preenchido no banco

### Teste 12: AnÃ¡lise com PLY Importado

```bash
if [ -n "$IMPORT_RECORD_ID" ]; then
  ANALYSIS2_RESPONSE=$(curl -s -X POST http://localhost:3000/api/$PROJECT_ID/analysis-full \
    -H "Content-Type: application/json" \
    -d "{\"recordId\": $IMPORT_RECORD_ID}")
  
  ANALYSIS2_ID=$(echo $ANALYSIS2_RESPONSE | jq -r '.analysisId')
  echo "AnÃ¡lise C2C iniciada: ID $ANALYSIS2_ID"
fi
```

**ValidaÃ§Ãµes:**
- âœ… AnÃ¡lise inicia sem erro
- âœ… Pula etapa 3DGS (usa PLY existente)
- âœ… Executa apenas comparaÃ§Ã£o C2C

### Teste 13: Deletar Projeto

```bash
DELETE_RESPONSE=$(curl -s -X DELETE http://localhost:3000/api/projects/$PROJECT_ID)
echo $DELETE_RESPONSE | jq

# Verificar que foi deletado
curl http://localhost:3000/api/projects/$PROJECT_ID
# Esperado: 404 Not Found
```

**ValidaÃ§Ãµes:**
- âœ… Projeto deletado do banco
- âœ… Arquivos fÃ­sicos removidos
- âœ… Registros e anÃ¡lises deletados (cascade)
- âœ… NÃ£o Ã© possÃ­vel acessar projeto deletado

---

## âš¡ Testes de Performance

### Teste de Carga BÃ¡sico

```bash
# Criar mÃºltiplos projetos rapidamente
for i in {1..10}; do
  curl -s -X POST http://localhost:3000/api/projects \
    -F "name=Projeto Load Test $i" \
    -F "modeloBim=@./tinker.obj" > /dev/null &
done
wait
echo "10 projetos criados"
```

### Teste de Upload Grande

```bash
# Criar arquivo grande (100MB)
dd if=/dev/zero of=large_bim.obj bs=1M count=100

# Testar upload
time curl -X POST http://localhost:3000/api/projects \
  -F "name=Projeto Arquivo Grande" \
  -F "modeloBim=@./large_bim.obj"

# Limpar
rm large_bim.obj
```

### Teste de ConcorrÃªncia

```bash
# Iniciar mÃºltiplas anÃ¡lises simultaneamente
for i in {1..5}; do
  curl -s -X POST http://localhost:3000/api/$PROJECT_ID/photo-processing-full \
    -F "name=Concorrente $i" \
    -F "fotos=@./test_foto_1.jpg" \
    -F "fotos=@./test_foto_2.jpg" \
    -F "fotos=@./test_foto_3.jpg" > /dev/null &
done
wait

# Verificar limite de concorrÃªncia (MAX_CONCURRENT_JOBS)
curl http://localhost:3000/api/analyses | jq '.jobs | length'
```

---

## ğŸ”— Testes de IntegraÃ§Ã£o

### Teste com Ferramentas Reais

Se vocÃª tem CloudCompare e COLMAP instalados:

```bash
# Configurar no .env
export IMAGE_PROCESSING_CLI="/caminho/para/colmap"
export BIM_COMPARISON_CLI="/caminho/para/CloudCompare"

# Reiniciar servidor
npm start

# Executar teste completo
./scripts/test-pipeline-mvp.sh
```

### Teste de IntegraÃ§Ã£o com Banco

```bash
# Conectar ao banco e verificar dados
docker exec -it metro-db psql -U postgres -d metro_pipeline -c "
SELECT 
  p.id, 
  p.name, 
  COUNT(DISTINCT r.id) as records_count,
  COUNT(DISTINCT a.id) as analyses_count
FROM project p
LEFT JOIN record r ON r.project_id = p.id
LEFT JOIN analysis a ON a.project_id = p.id
GROUP BY p.id, p.name
ORDER BY p.id DESC
LIMIT 10;
"
```

---

## ğŸ“Š ValidaÃ§Ã£o de Dados

### Verificar Integridade dos Dados

```bash
# Script de validaÃ§Ã£o
cat > validate_data.sh << 'EOF'
#!/bin/bash

echo "=== ValidaÃ§Ã£o de Dados ==="

# Projetos sem BIM
echo "Projetos sem arquivo BIM:"
docker exec metro-db psql -U postgres -d metro_pipeline -t -c "
SELECT COUNT(*) FROM project p
WHERE NOT EXISTS (
  SELECT 1 FROM pg_ls_dir('$(pwd)/src/shared/data/uploads') f
  WHERE f = p.bim_path
);
"

# Registros sem fotos
echo "Registros sem fotos:"
docker exec metro-db psql -U postgres -d metro_pipeline -t -c "
SELECT COUNT(*) FROM record 
WHERE uploaded_files_paths IS NULL OR uploaded_files_paths = '[]'::jsonb;
"

# AnÃ¡lises Ã³rfÃ£s
echo "AnÃ¡lises com projeto/registro inexistente:"
docker exec metro-db psql -U postgres -d metro_pipeline -t -c "
SELECT COUNT(*) FROM analysis a
WHERE NOT EXISTS (SELECT 1 FROM project p WHERE p.id = a.project_id)
   OR NOT EXISTS (SELECT 1 FROM record r WHERE r.id = a.record_id);
"
EOF

chmod +x validate_data.sh
./validate_data.sh
```

---

## ğŸ“ˆ Monitoramento

### MÃ©tricas Importantes

```bash
# NÃºmero de projetos
curl -s http://localhost:3000/api/projects | jq 'length'

# NÃºmero de anÃ¡lises por status
curl -s http://localhost:3000/api/analyses | jq '
  .jobs | group_by(.status) | map({status: .[0].status, count: length})
'

# AnÃ¡lises em processamento
curl -s http://localhost:3000/api/analyses | jq '
  .jobs | map(select(.status == "processing")) | length
'

# EspaÃ§o em disco usado
du -sh src/shared/data/uploads src/shared/data/outputs
```

### Logs do Servidor

```bash
# Se usando PM2
pm2 logs

# Se rodando diretamente
# Verificar saÃ­da do console para erros
```

---

## ğŸš¨ Troubleshooting

### Problema: AnÃ¡lise nÃ£o completa

**Sintomas:** Status fica em "processing" indefinidamente

**SoluÃ§Ãµes:**
1. Verificar logs da anÃ¡lise:
   ```bash
   curl http://localhost:3000/api/analyses/$ANALYSIS_ID | jq '.logs[-10:]'
   ```

2. Verificar se ferramenta CLI estÃ¡ funcionando:
   ```bash
   bash tools/fake_3dgs.sh --input test --output /tmp/test.ply
   ```

3. Verificar espaÃ§o em disco:
   ```bash
   df -h
   ```

4. Verificar processos travados:
   ```bash
   ps aux | grep node
   ```

### Problema: Upload falha

**Sintomas:** Erro 413 ou timeout

**SoluÃ§Ãµes:**
1. Verificar limite de tamanho no Multer (5GB padrÃ£o)
2. Verificar espaÃ§o em disco
3. Verificar timeout do servidor
4. Verificar tamanho do arquivo

### Problema: Banco de dados nÃ£o conecta

**Sintomas:** Erro de conexÃ£o Prisma

**SoluÃ§Ãµes:**
1. Verificar se Docker estÃ¡ rodando:
   ```bash
   docker ps | grep metro-db
   ```

2. Verificar DATABASE_URL no .env
3. Testar conexÃ£o manual:
   ```bash
   docker exec -it metro-db psql -U postgres -d metro_pipeline -c "SELECT 1;"
   ```

---

## ğŸ“ Checklist Final de ProduÃ§Ã£o

Antes de considerar o sistema pronto para produÃ§Ã£o:

- [ ] Todos os testes funcionais passaram
- [ ] Performance aceitÃ¡vel (< 30s para processamento mock)
- [ ] Integridade de dados validada
- [ ] Logs configurados e monitorados
- [ ] Backup do banco configurado
- [ ] VariÃ¡veis de ambiente seguras
- [ ] Ferramentas CLI funcionando (se usando)
- [ ] DocumentaÃ§Ã£o atualizada
- [ ] Equipe treinada no uso

---

## ğŸ¯ PrÃ³ximos Passos

ApÃ³s validar todos os testes:

1. Configurar monitoramento contÃ­nuo
2. Configurar alertas para falhas
3. Documentar procedimentos operacionais
4. Treinar equipe de suporte
5. Estabelecer rotina de backups

---

**Ãšltima atualizaÃ§Ã£o:** $(date +"%Y-%m-%d")

